### SuperComputing

### What are supercomputers?

The interest of supercomputers has grown immensely since the initial design of the Control Data Corporation 6600 by Seymour Cray in 1964. With the fairly recent development of supercomputers like the Chinese Sunway Exascale and African Toubkal, we’ve reached an era of supercomputing that was not imaginable 50+ years ago.  Compared to the original designs of supercomputers in the 1960’s, these newer machines are like formula 1 race cars. It’s time to take a step back and reflect on the history of supercomputers to better understand how far we’ve come in this field..

So what exactly are supercomputers? Supercomputers are massively complex machines designed to perform supercomputing. Supercomputing is the act of processing data using the computing resources of multiple systems that work in unison. Supercomputers today are capable of performing over 5.02 petaflops of processing power. These machines contain thousands of nodes and are capable of performing massive scenario processing for cases in weather, life sciences, manufacturing, and other key fields. 

Supercomputing enables problem solving on a whole different level but at the cost of space, money, and energy. Massive amounts of data in previous decades that were unable to be processed can be processed in mere seconds with the growth of these massive machines. Before we breakdown what current machines can do it's better to understand how the initial supercomputers were created. 

### The First Supercomputers

Seymour cray is the name synonymously associated with supercomputers. His unofficial title is known as “the grandfather of supercomputers”.  In 1964 Seymour Cray designed one of the first computers capable of fast computations. These new types of machines were soon to be named “supercomputers”. The CDC 6600 was capable of top computing speeds of around 3 million floating point operations per second (megaFlops).It consisted of over 400,000 transistors, and more than 100 miles of hand-wiring. These numbers at the time were never before seen by a computer and provided a foundation for what was to come throughout the next several decades. 

After Seymour Cray's initial creation of the CDC 6600 he left to form his own company known as Cray Research. During this time in his life he continued to design new supercomputers that would continue to progress the field of supercomputers. The design of the Cray-1 in 1976, and then Cray-2 in 1985 allowed for a new supercomputing architecture that utilized vector processors. Vector processors operate on linear arrays of 64-bit floating-point numbers which are able to get quicker results in comparison to previous processors models. Despite the interest in supercomputing declining after the end of the cold war, Seymour Cray continued to find new ways to find funding to develop new systems. 

Unfortunately Seymour died in a car accident in 1996, but despite his death his ideas and concepts continued to live in future supercomputer models.. Japanese companies such as NEC, Fujitsu, and Hitachi continued to build vector-based supercomputers using his technology. During a brief period from 1993 to 1996, Fujitsu held the world’s fastest supercomputer. Boasting speeds above 600 gigaFLOPS which was influenced by Seymour Cray’s Cray machines.


### African Supercomputer “Toubkal”

Toubkal (named after the moroccan mountain) is one of the newest supercomputers that demonstrates where the field has grown since the days of the CDC 6000. The system boasts a peak of around 5.02 petaflops. It holds 244TB of memory and over 1,300 nodes containing 71,232 Intel Xeon Platinum 8276L cores. 

The system ranks in at 98th out of the top 500 supercomputers but is rated as the number 1 supercomputer in the continent of Africa. The system is currently within the Mohammed VI Polytechnic University in Ben Guerir, Morocco. 

When it comes to the use of “Toubkal”, the current objectives that are being given to the machine are as such:
- Modeling the genomes of African plants in need of protection
- modeling the genomes of microorganisms to better understand soil fertility
- processing satellite data for improved agricultural management
- analyzing meteorological data to aid in the integration of renewable energy projects

The Toubkal gives an insight into how far supercomputers have come and how the continent of Africa is working to become one of the premier countries in super computing usage to solve issues plaguing the continent. 

### China’s Sunway Exascale Supercomputer

When it comes to the powerhouses of supercomputer development, the United States and China have constantly been in a class to develop some of the premiere machines. The title of the fastest and most powerful machine has gone back and forth between both countries but China hopes to take back that title with their newest and most powerful machine, the Sunway Exascale Supercomputer.

The computer was first announced in 2016 at the International Supercomputing Conference.  The system is the successor to the TaihuLight System which was ranked as the fastest supercomputer in the world from June 2016 through November 2018. Despite the TaihuLight System no longer being the most powerful it currently stands at the fourth most powerful. 

The Sunway system architecture is a hybrid system that utilizes a combination of serial and parallel components.

The machine utilizes a core group named SW52020 which in total holds at 520 cores for its entire layout. This allowed the machine to be twice as fast as its predecessor model. By effectively doubling the computing elements, it comes in at top speeds of 6.12 teraflops per chip. Overall the system can perform at speeds of around 125.4 petaflops across its 40,960 nodes. 

With twice the computing power as its predecessor the Sunway Exascale Supercomputer currently comes in at 3rd in the global ranking for most powerful supercomputers the world, just behind the Sierra, Lawrence Livermore National Laboratory and Summit,Oak Ridge National Laboratory. 


### Efficient Supercomputing

When it comes to the increase of efficiency, speed, and power there is typically always a tradeoff. In the world of supercomputing that trade-off for decades of growth is the need for money, space, and energy. With the development of faster, bigger, and better machines it has put an immense strain on the field with a potential ceiling in sight. The only way to overcome this is to develop new and efficient ways to address the problems that are currently affecting the supercomputing field. 

### Conclusion
When it comes to solving some of the hardest problems in existence it requires lots of data to be processed. Data that isn’t easily digestible by your average computer. Through the use of supercomputers we are able to develop solutions for  improved agricultural management, understanding of  soil fertility, and improved agricultural management. From the original cray-1 to the Toubkal supercomputer, progress has been made in the past 60+ years that has opened new doors for research and discovery. Despite there being massive improvements in the development of these machines it's important to note that current machines are reaching a  ceiling based on Moore’s Law of Consumption. The key to breaking past this ceiling is to find new and sustainable models for supercomputing that help to overcome the current barriers facing newer models such as power/space consumption. When it comes to power and speed these machines help to process data that was once imaginable, and because of that their field is one of the most exciting and useful tools for developing a better future. 


The development of more powerful supercomputers has led others to notice a negative trend in power consumption for supercomputers. This trend was discovered when comparing how much power nodes require in comparison to Moore’s Law for Power Consumption. It’s stated that the power consumption of computer nodes doubles every 18 months. This correlates with Moore’s law, which states that the number of transistors per square inch on a processor doubles every 18 months. With immensely high temperatures being created by these systems they require cooling to not render the equipment useless. This increase of temperature with each powerful new system created it causes a directly proportional to power consumption

Green Destiny is an example of what supercomputers could be in the future if a more resources concise approach is taken. This machine utilizes a hardware-driven design that maximizes energy savings in an attempt to minimize the impact on the overall performance. Most supercomputers utilize a software-driven design that requires lots of power and cooling in order to render them useful. It’s speed and raw power aren’t like it’s peers but the machine serves as an example of how to avoid running into issues with Moore’s Law for Power Consumption. It serves as an alternative supercomputing model whose focus is on efficiency, reliability, availability, and versatility. 

